{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PMcoder84/prompt-playbook/blob/main/PromptEngineeringFundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nHALL7ycNPrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35321164-8368-40b0-af21-2de12e4ca978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.8/450.8 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langgraph-prebuilt 1.0.5 requires langchain-core>=1.0.0, but you have langchain-core 0.3.80 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install langchain-groq langchain==0.3.25 duckduckgo-search langchain_community ddgs langchain-community  --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import getpass"
      ],
      "metadata": {
        "id": "lxLo-aIyNWzg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = getpass.getpass(\"Enter your Groq API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QxiKyoLNbVV",
        "outputId": "e19c5b66-311c-4752-b2b2-735133d1b5f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    api_key=api_key\n",
        ")"
      ],
      "metadata": {
        "id": "0UpjXebHNhRB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain-core langchain-groq langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G2CTuLlh_V-d",
        "outputId": "fe0f2dbc-1f91-43fc-ba96-7a72bed2b96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.80)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.12/dist-packages (0.3.8)\n",
            "Collecting langchain-groq\n",
            "  Using cached langchain_groq-1.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.25)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.1.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.3.45)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: groq<1.0.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.37.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.4)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
            "Downloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-1.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading langchain-1.1.0-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, langchain-groq, langchain\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.80\n",
            "    Uninstalling langchain-core-0.3.80:\n",
            "      Successfully uninstalled langchain-core-0.3.80\n",
            "  Attempting uninstall: langchain-groq\n",
            "    Found existing installation: langchain-groq 0.3.8\n",
            "    Uninstalling langchain-groq-0.3.8:\n",
            "      Successfully uninstalled langchain-groq-0.3.8\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.25\n",
            "    Uninstalling langchain-0.3.25:\n",
            "      Successfully uninstalled langchain-0.3.25\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-community 0.3.25 requires langchain<1.0.0,>=0.3.25, but you have langchain 1.1.0 which is incompatible.\n",
            "langchain-community 0.3.25 requires langchain-core<1.0.0,>=0.3.65, but you have langchain-core 1.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-1.1.0 langchain-core-1.1.0 langchain-groq-1.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain",
                  "langchain_core",
                  "langchain_groq"
                ]
              },
              "id": "5683e4411c4d4bdbbb7e99a4dcdd3811"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "single_turn_prompt = \"Tell me about China\"\n",
        "print(llm.invoke(single_turn_prompt).content)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oKp8skHZNnwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c6f1de-bff5-4efa-9a7d-79e054700068"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China, officially known as the People's Republic of China (PRC), is a country with a rich history, diverse culture, and vast territory. It is the world's most populous country, with over 1.44 billion people, and is the third-largest country by land area, after Russia and Canada.\n",
            "\n",
            "**Geography**\n",
            "\n",
            "China is located in East Asia, bordered by:\n",
            "\n",
            "* India, Nepal, and Bhutan to the west\n",
            "* Mongolia and Russia to the north\n",
            "* North Korea to the northeast\n",
            "* Vietnam, Laos, and Myanmar to the south\n",
            "* Taiwan, which is claimed by China as a province, to the east\n",
            "\n",
            "The country's terrain is varied, with mountains, forests, and deserts. The Himalayas, the world's highest mountain range, form the southern border. The Great Wall of China, a UNESCO World Heritage Site, is one of the country's most famous landmarks.\n",
            "\n",
            "**History**\n",
            "\n",
            "China has a long and complex history, dating back to the Shang Dynasty (16th-11th centuries BCE). The Qin Dynasty (221-206 BCE) unified the various warring states, establishing the first imperial system. The Han Dynasty (206 BCE-220 CE) expanded China's borders, established trade with other countries, and developed a writing system.\n",
            "\n",
            "The Mongols conquered China in the 13th century, and the Ming Dynasty (1368-1644 CE) restored Chinese rule. The Qing Dynasty (1644-1912 CE) was the last imperial dynasty, which was overthrown by the Chinese Revolution.\n",
            "\n",
            "**Government and Politics**\n",
            "\n",
            "China is a one-party state, with the Communist Party of China (CPC) holding power since 1949. The government is a centralized, authoritarian regime, with a president as the head of state and a premier as the head of government.\n",
            "\n",
            "**Economy**\n",
            "\n",
            "China is the world's second-largest economy, after the United States, with a GDP of over $16 trillion. The country has experienced rapid economic growth since the 1980s, driven by industrialization, urbanization, and technological innovation.\n",
            "\n",
            "**Culture**\n",
            "\n",
            "Chinese culture is rich and diverse, with a long history of art, literature, music, and philosophy. The country is home to many UNESCO World Heritage Sites, including the Great Wall, the Forbidden City, and the Terracotta Army.\n",
            "\n",
            "**Cuisine**\n",
            "\n",
            "Chinese cuisine is renowned for its variety, with different regions and provinces having their own unique dishes. Popular Chinese dishes include Peking duck, dumplings, noodles, and hot pot.\n",
            "\n",
            "**Demographics**\n",
            "\n",
            "China has a population of over 1.44 billion people, with a population growth rate of 0.3%. The country has a diverse population, with over 50 ethnic groups, including the Han, Uyghur, and Tibetan.\n",
            "\n",
            "**Education**\n",
            "\n",
            "Education is highly valued in Chinese culture, with a literacy rate of over 95%. The country has a well-developed education system, with top universities such as Tsinghua University and Peking University.\n",
            "\n",
            "**Challenges**\n",
            "\n",
            "China faces several challenges, including:\n",
            "\n",
            "* Environmental degradation, such as air and water pollution\n",
            "* Economic inequality and unemployment\n",
            "* Territorial disputes with neighboring countries\n",
            "* Human rights concerns, including freedom of speech and assembly\n",
            "\n",
            "Overall, China is a country with a rich history, diverse culture, and vast territory. Its rapid economic growth and technological innovation have made it a major player in the global economy, but the country also faces significant challenges that need to be addressed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "single_turn_prompt_new = \"Tell me what is its capital?\"\n",
        "print(llm.invoke(single_turn_prompt_new).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72yG4HybgjAj",
        "outputId": "9f27c28f-99c0-4cf0-881f-193e2e12ecfc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I can't confirm what you are referring to. Can you provide more context or information about the topic you would like to know about?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "structured_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Provide a brief explanation of {topic} and list its three main components.\"\n",
        ")\n",
        "\n",
        "chain = structured_prompt | llm\n",
        "print(chain.invoke({\"topic\": \"Water\"}).content)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oDFLmFM3QDzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f64c13d-486e-44a7-de79-c3ca3437e20a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Water is a clear, colorless, odorless, and tasteless liquid substance essential for life on Earth. It is a vital component of the Earth's ecosystem, making up approximately 71% of the planet's surface. Water is a chemical compound composed of two hydrogen atoms and one oxygen atom (H2O).\n",
            "\n",
            "The three main components of water are:\n",
            "\n",
            "1. **Hydrogen (H)**: Hydrogen atoms make up about 2/3 of water's molecular weight, providing water with its chemical properties and reactivity.\n",
            "2. **Oxygen (O)**: Oxygen atoms are the central component of water, making up about 1/3 of its molecular weight. Oxygen's high electronegativity gives water its cohesion and surface tension.\n",
            "3. **Electrons**: The electrons in water molecules are shared between the hydrogen and oxygen atoms, forming covalent bonds. The arrangement of these electrons is responsible for water's polar nature and its ability to form hydrogen bonds.\n",
            "\n",
            "These components work together to create water's unique properties, which are essential for life on Earth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=False,\n",
        "    memory=ConversationBufferMemory()\n",
        ")\n",
        "\n",
        "print(conversation.predict(input=\"Tell me about the company Microsoft\"))\n",
        "print(conversation.predict(input=\"How about Target?\"))\n",
        "print(conversation.predict(input=\"Where is it headquartered?\"))"
      ],
      "metadata": {
        "id": "xSzFoG7bQZ-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c27542-1d07-4518-ab96-57329aa308d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3553094292.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory=ConversationBufferMemory()\n",
            "/tmp/ipython-input-3553094292.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  conversation = ConversationChain(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Microsoft is a multinational technology company that was founded on April 4, 1975, by Bill Gates and Paul Allen. It's headquartered in Redmond, Washington, United States, and is one of the largest and most influential software companies in the world. The company's name is a combination of the words \"microcomputer\" and \"software,\" which was fitting given the focus of their early work.\n",
            "\n",
            "Microsoft is perhaps best known for developing the Windows operating system, which has become the dominant desktop platform for personal computers. The first version of Windows, Windows 1.0, was released on November 20, 1985. Since then, the company has released numerous versions of Windows, including Windows 95, Windows XP, Windows 7, and Windows 10, each with its own set of features and improvements.\n",
            "\n",
            "In addition to Windows, Microsoft is also the developer of the Office software suite, which includes applications such as Word, Excel, PowerPoint, and Outlook. The company has also made significant investments in cloud computing, artificial intelligence, and gaming, with the acquisition of companies such as LinkedIn, GitHub, and Xbox.\n",
            "\n",
            "Today, Microsoft is a leader in the tech industry, with a market capitalization of over $2 trillion and a global workforce of over 180,000 employees. The company's mission is to empower every person and organization on the planet to achieve more, and its products and services are used by millions of people around the world.\n",
            "Target Corporation is an American retailing company that was founded in 1902 by George Dayton in Minneapolis, Minnesota. It was originally a dry goods store called Dayton's Dry Goods Company, but it eventually expanded into a department store and eventually into the modern retail chain that we know today. The company is headquartered in Minneapolis, Minnesota, and operates over 1,900 stores across the United States.\n",
            "\n",
            "Target is perhaps best known for its wide range of products, which include clothing, home goods, electronics, and toys. The company has made significant efforts to compete with other major retailers, such as Walmart and Amazon, by offering a unique shopping experience through its upscale design aesthetic, known as the \"Target Look.\"\n",
            "\n",
            "In recent years, Target has also invested heavily in its e-commerce platform, allowing customers to shop online and have items delivered to their homes or in-store for pickup. The company has also partnered with various brands, such as Cat & Jack and Art Class, to offer exclusive products that cater to a wide range of tastes and needs.\n",
            "\n",
            "Today, Target is a leading retailer in the United States, with over 360,000 employees and a market capitalization of around $50 billion. The company's mission is to make target a beloved shopping destination for guests by delivering outstanding value, continuous innovation and an exceptional shopping experience by consistently fulfilling our Expect More. Pay Less. brand promise.\n",
            "Target Corporation is headquartered in Minneapolis, Minnesota, United States. The company's main office, known as the Chicago office, also operates out of Chicago, Illinois, but Minneapolis is its primary location.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.predict(input=\"Where is it headquartered?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUNOrako9ZxN",
        "outputId": "dbecdd29-5859-4278-f38b-00771524df61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You've already asked me that question earlier, and I provided the answer that Target Corporation is headquartered in Minneapolis, Minnesota, United States. The exact address is 1000 Nicollet Mall, Minneapolis, MN 55403. \n",
            "\n",
            "If you're looking for another piece of information, I'd be happy to try and help.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt Template**"
      ],
      "metadata": {
        "id": "zN0K0dusTIy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic_template = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Explain {topic} in simple terms for a beginner.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "9jJ4M13YTRKk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_prompt = basic_template.format(topic=\"machine learning\")\n",
        "print(\"Generated Prompt:\", topic_prompt)\n",
        "print(\"\\nResponse:\")\n",
        "response = llm.invoke(topic_prompt)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "mKYDTpUpTa5N",
        "outputId": "887584f8-c42b-4704-e3d9-492cbeb39857",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Prompt: Explain machine learning in simple terms for a beginner.\n",
            "\n",
            "Response:\n",
            "**What is Machine Learning?**\n",
            "\n",
            "Machine learning is a type of artificial intelligence (AI) that allows computers to learn from data without being explicitly programmed. Think of it like this: you're teaching a computer to recognize pictures of cats and dogs. You don't need to tell it, \"Hey, this is a cat and this is a dog.\" Instead, you give it a bunch of pictures and say, \"Figure it out yourself.\"\n",
            "\n",
            "**How Does it Work?**\n",
            "\n",
            "Machine learning involves several steps:\n",
            "\n",
            "1. **Data Collection**: Gather a large amount of data related to the problem you're trying to solve (e.g., pictures of cats and dogs).\n",
            "2. **Data Preprocessing**: Clean and prepare the data for use (e.g., resizing images).\n",
            "3. **Model Training**: Use algorithms to train a model on the data (e.g., a neural network).\n",
            "4. **Model Evaluation**: Test the model on new, unseen data to see how well it performs.\n",
            "5. **Model Improvement**: Refine the model based on the results and repeat the process.\n",
            "\n",
            "**Types of Machine Learning**\n",
            "\n",
            "There are three main types of machine learning:\n",
            "\n",
            "1. **Supervised Learning**: The computer is trained on labeled data, where the correct output is already known (e.g., classifying pictures of cats and dogs).\n",
            "2. **Unsupervised Learning**: The computer is trained on unlabeled data, where it discovers patterns and relationships (e.g., clustering similar customers).\n",
            "3. **Reinforcement Learning**: The computer learns through trial and error, receiving rewards or penalties for its actions (e.g., playing games).\n",
            "\n",
            "**Real-World Applications**\n",
            "\n",
            "Machine learning is used in many areas, including:\n",
            "\n",
            "1. **Image Recognition**: Self-driving cars, facial recognition, and medical image analysis.\n",
            "2. **Natural Language Processing**: Language translation, chatbots, and text analysis.\n",
            "3. **Predictive Maintenance**: Predicting equipment failures and scheduling maintenance.\n",
            "4. **Recommendation Systems**: Suggesting products or services based on user behavior.\n",
            "\n",
            "**Key Concepts**\n",
            "\n",
            "1. **Algorithms**: The rules used to train and improve models.\n",
            "2. **Models**: The representations of data used to make predictions.\n",
            "3. **Bias-Variance Tradeoff**: The balance between accuracy and complexity in models.\n",
            "4. **Overfitting**: When a model becomes too complex and performs poorly on new data.\n",
            "\n",
            "**Conclusion**\n",
            "\n",
            "Machine learning is a powerful tool for automating decision-making and solving complex problems. By understanding the basics of machine learning, you can begin to explore its applications and develop your skills in this exciting field.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_template = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"audience\", \"tone\", \"length\"],\n",
        "    template=\"\"\"\n",
        "You are an expert educator. Create a {length} explanation about {subject}\n",
        "for {audience}. Use a {tone} tone and include practical examples.\n",
        "\n",
        "Topic: {subject}\n",
        "Target Audience: {audience}\n",
        "Tone: {tone}\n",
        "Length: {length}\n",
        "\n",
        "Your explanation:\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "NBLbPqnmTk_j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_prompt = advanced_template.format(\n",
        "    subject=\"Biology\",\n",
        "    audience=\"College Students\",\n",
        "    tone=\"Professional\",\n",
        "    length=\"100 words\"\n",
        ")\n",
        "print(llm.invoke(advanced_prompt).content)"
      ],
      "metadata": {
        "id": "KmtAzmf6TxMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17e7240-6490-458c-aa96-b2c2f16a2f03"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Biology is the scientific study of living organisms and their interactions with the environment. It encompasses various disciplines, including molecular biology, ecology, and genetics. By examining the structure and function of cells, biomolecules, and organisms, biologists can understand complex phenomena such as evolution, development, and disease. Practical applications of biology include genetic engineering, agricultural biotechnology, and medical research. For instance, understanding the genetic basis of cancer can inform the development of targeted therapies. Additionally, studying plant physiology can improve crop yields and food security. Through biology, students can gain a deeper understanding of the natural world and its many complexities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeroshot prompting**"
      ],
      "metadata": {
        "id": "oZ6q0oUcVpnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_chain(prompt_template):\n",
        "    \"\"\"\n",
        "    Create a LangChain chain with the given prompt template.\n",
        "\n",
        "    Args:\n",
        "        prompt_template (str): The prompt template string.\n",
        "\n",
        "    Returns:\n",
        "        LLMChain: A LangChain chain object.\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate.from_template(prompt_template)\n",
        "    return prompt | llm"
      ],
      "metadata": {
        "id": "UEogP6jHVosp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "direct_task_prompt = \"\"\"Classify the sentiment of the following text as positive, negative, or neutral.\n",
        "Do not explain your reasoning, just provide the classification.\n",
        "\n",
        "Text: {text}\n",
        "\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "direct_task_chain = create_chain(direct_task_prompt)\n",
        "\n",
        "# Test the direct task specification\n",
        "texts = [\n",
        "    \"The product met my expectation. Great value for money\",\n",
        "    \"The weather today is quite typical for this time of year.\",\n",
        "    \"I wish the restaurant wait times were shorter. We wasted a lot of time\"\n",
        "]\n",
        "\n",
        "for text in texts:\n",
        "    result = direct_task_chain.invoke({\"text\": text}).content\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Sentiment: {result}\")"
      ],
      "metadata": {
        "id": "cPKSNnWWW-qZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d000dbb9-2828-42e2-d772-00d6c39220d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: The product met my expectation. Great value for money\n",
            "Sentiment: Positive\n",
            "Text: The weather today is quite typical for this time of year.\n",
            "Sentiment: Neutral\n",
            "Text: I wish the restaurant wait times were shorter. We wasted a lot of time\n",
            "Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multistep_reasoning_prompt = \"Explain the steps involved in solving the {math_problem} and then solve the math problem step by step\"\n",
        "multistep_reasoning_chain = create_chain(multistep_reasoning_prompt)\n",
        "\n",
        "problem =\"3*4+(6-4)\"\n",
        "result = multistep_reasoning_chain.invoke({\"math_problem\": problem}).content\n",
        "print(f\"Problem: {problem}\")\n",
        "print(f\"Result: {result}\")"
      ],
      "metadata": {
        "id": "Dr9OgBKKYVAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DsPY to control output**"
      ],
      "metadata": {
        "id": "c1YT-vE4bsiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dspy-ai"
      ],
      "metadata": {
        "id": "qNxSYe8AbwQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e67d99-24ae-42c3-bbde-835d9798af95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dspy-ai\n",
            "  Downloading dspy_ai-3.0.4-py3-none-any.whl.metadata (285 bytes)\n",
            "Collecting dspy>=3.0.4 (from dspy-ai)\n",
            "  Downloading dspy-3.0.4-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting backoff>=2.2 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.5.2)\n",
            "Requirement already satisfied: openai>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.8.1)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2025.11.3)\n",
            "Requirement already satisfied: orjson>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.11.4)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.67.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.32.4)\n",
            "Collecting optuna>=3.4.0 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.12.3)\n",
            "Collecting magicattr>=0.1.6 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting litellm>=1.64.0 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading litellm-1.80.7-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting diskcache>=5.6.0 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting json-repair>=0.30.0 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading json_repair-0.54.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (9.1.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.11.0)\n",
            "Collecting asyncer==0.0.8 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools>=5.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (6.2.2)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.1.2)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (13.9.4)\n",
            "Requirement already satisfied: pillow>=10.1.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (11.3.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.0.2)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.6.0)\n",
            "Collecting gepa==0.0.17 (from gepa[dspy]==0.0.17->dspy>=3.0.4->dspy-ai)\n",
            "  Downloading gepa-0.0.17-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (4.15.0)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.3.1)\n",
            "Collecting fastuuid>=0.13.0 (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai)\n",
            "  Downloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting grpcio<1.68.0,>=1.62.3 (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai)\n",
            "  Downloading grpcio-1.67.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (4.25.1)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.2.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.22.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.17.2)\n",
            "Collecting colorlog (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (2.0.44)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (6.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->dspy>=3.0.4->dspy-ai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->dspy>=3.0.4->dspy-ai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->dspy>=3.0.4->dspy-ai) (2025.11.12)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (2.19.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.22.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.3.10)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.29.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy>=3.0.4->dspy-ai) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.2.0)\n",
            "Downloading dspy_ai-3.0.4-py3-none-any.whl (1.1 kB)\n",
            "Downloading dspy-3.0.4-py3-none-any.whl (285 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.2/285.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading gepa-0.0.17-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.54.2-py3-none-any.whl (29 kB)\n",
            "Downloading litellm-1.80.7-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.67.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: magicattr, json-repair, grpcio, gepa, fastuuid, diskcache, colorlog, backoff, asyncer, optuna, litellm, dspy, dspy-ai\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.76.0\n",
            "    Uninstalling grpcio-1.76.0:\n",
            "      Successfully uninstalled grpcio-1.76.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires grpcio>=1.71.2, but you have grpcio 1.67.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asyncer-0.0.8 backoff-2.2.1 colorlog-6.10.1 diskcache-5.6.3 dspy-3.0.4 dspy-ai-3.0.4 fastuuid-0.14.0 gepa-0.0.17 grpcio-1.67.1 json-repair-0.54.2 litellm-1.80.7 magicattr-0.1.6 optuna-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "lm = dspy.LM(\n",
        "    model=\"groq/llama-3.1-8b-instant\",\n",
        "    api_key=api_key,\n",
        "    max_tokens=600\n",
        ")\n",
        "\n",
        "dspy.settings.configure(lm=lm)\n"
      ],
      "metadata": {
        "id": "KiNzh02nb2eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CityInfo(dspy.Signature):\n",
        "    \"\"\"Return structured facts about a city in YAML format.\"\"\"\n",
        "    city = dspy.InputField(desc=\"Name of the city\")\n",
        "    output = dspy.OutputField(\n",
        "        desc=\"YAML with keys: history, culture, food\"\n",
        "    )"
      ],
      "metadata": {
        "id": "qaTsqGStcOKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "city_info_module = dspy.Predict(CityInfo)\n"
      ],
      "metadata": {
        "id": "03nNROBdcXmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = city_info_module(city=\"London\")\n",
        "print(response.output)"
      ],
      "metadata": {
        "id": "BH5ABEY6ch5Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c95b3bf-8db8-4483-d8e4-e95adb133374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "history:\n",
            "  - Roman Empire (43-410 AD)\n",
            "  - Anglo-Saxon Kingdom (410-1066 AD)\n",
            "  - Norman Conquest (1066 AD)\n",
            "  - Medieval Period (1066-1485 AD)\n",
            "  - Renaissance and Enlightenment (1485-1800 AD)\n",
            "  - Industrial Revolution (1800-1900 AD)\n",
            "  - World War I and II (1914-1945 AD)\n",
            "culture:\n",
            "  - British culture\n",
            "  - The British Museum\n",
            "  - Royal Family\n",
            "  - West End theater\n",
            "  - London Symphony Orchestra\n",
            "food:\n",
            "  - Fish and chips\n",
            "  - Bangers and mash\n",
            "  - Full English breakfast\n",
            "  - Sunday roast\n",
            "  - English afternoon tea\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cities = [\"Tokyo\", \"Mumbai\", \"London\",\"Paris\"]\n",
        "\n",
        "for city in cities:\n",
        "    print(f\"\\n--- Information about {city} ---\")\n",
        "    response = city_info_module(city=city)\n",
        "    print(response.output)"
      ],
      "metadata": {
        "id": "MgmcZGtmcouV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e627bf75-66fb-4e4c-f3ee-ad42042e7a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Information about Tokyo ---\n",
            "{\n",
            "    \"history\": \"Tokyo has a rich history dating back to 1457 when it was a small fishing village named Edo. Over time, it grew to become the center of the Japanese government and, in 1868, it was renamed Tokyo, meaning 'Eastern Capital.'\",\n",
            "    \"culture\": \"Tokyo's vibrant culture can be seen in its unique blend of traditional and modern architecture, fashion, and cuisine. The city is famous for its pop culture, anime, and manga, as well as its beautiful temples and shrines, such as the Meiji Shrine and Sensō-ji Temple.\",\n",
            "    \"food\": \"Tokyo's food scene is world-renowned for its fresh ingredients, seasonality, and innovative chefs. Some popular dishes include sushi, ramen, tempura, and yakitori. Visitors can also try street food at the Tsukiji Outer Market or visit the trendy restaurants in Harajuku.\"\n",
            "}\n",
            "\n",
            "--- Information about Mumbai ---\n",
            "{\n",
            "  \"history\": \"Mumbai is the largest metropolis of India and has a rich history dating back to the 16th century. It was a small fishing village called 'Bhappagad' before the British East India Company took control over it in the 17th century and renamed it 'Bombay'.\",\n",
            "  \"culture\": \"Mumbai has a diverse culture with influences from various Indian traditions, British colonial architecture, and the influence of migrants from all parts of India. It's known as the 'City of Dreams' due to its vibrant film industry and music scene.\",\n",
            "  \"food\": \"Mumbai's cuisine is a blend of traditional Indian and street food, with popular dishes like vada pav, pani puri, bhelpuri, and misal pav. You can also find various seafood options, as well as traditional Parsi, Gujarati, and Maharashtrian cuisines.\"\n",
            "}\n",
            "\n",
            "--- Information about London ---\n",
            "{\n",
            "    \"history\": \"London has a rich history dating back to the Roman era. It was the capital of the Roman province of Britain, known as Londinium. The city's history continued with the Anglo-Saxons and the Viking invasions. In the Middle Ages, London became a major commercial center and a center of the British Empire.\",\n",
            "    \"culture\": \"London is known for its diverse cultural scene. The city is home to many museums, galleries, and performance venues. The National Gallery, the Tate Modern, and the British Museum are just a few examples of the city's world-class cultural institutions. London also hosts many festivals throughout the year, such as the Notting Hill Carnival and the London Marathon.\",\n",
            "    \"food\": \"London's cuisine is a fusion of traditional British and international flavors. Classic British dishes include fish and chips, roast beef, and bangers and mash. The city is also known for its culinary diversity, with many international restaurants serving food from around the world. Some popular foods in London include traditional Indian and Chinese cuisine as well as traditional British food served at pubs and cafes.\"\n",
            "}\n",
            "\n",
            "--- Information about Paris ---\n",
            "{\n",
            "    \"history\": \"Paris has a rich and varied history dating back to the Iron Age. It was a major centre of the Roman Empire and later became the capital of France. The city has been the site of many significant events, including the French Revolution and the Belle Époque.\",\n",
            "    \"culture\": \"Paris is known for its art, architecture, and cultural heritage. It is home to many famous museums, galleries, and performance venues, and is often referred to as the 'City of Light'. The city is also famous for its fashion, cuisine, and nightlife.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Few Shot Prompting**"
      ],
      "metadata": {
        "id": "36JolNz7djXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Few-shot prompting example for sentiment classification in e-commerce\n",
        "\n",
        "few_shot_prompt_template = \"\"\"Classify the sentiment of the following customer product review\n",
        "as positive, negative, or neutral.\n",
        "\n",
        "Here are a few examples:\n",
        "\n",
        "Review: The shoes fit perfectly and the quality is amazing.\n",
        "Sentiment: positive\n",
        "\n",
        "Review: The delivery was late and the product was damaged.\n",
        "Sentiment: negative\n",
        "\n",
        "Review: The packaging was okay, nothing special.\n",
        "Sentiment: neutral\n",
        "\n",
        "Review: {review}\n",
        "Sentiment:\n",
        "Answer concisely in 1 or two words\n",
        "\n",
        "Make sure the output format is clearly folowed as Sentiment: <positive/negative/neutral>\n",
        "\"\"\"\n",
        "\n",
        "# Assuming you have a helper function that wraps the LLM call\n",
        "few_shot_chain = create_chain(few_shot_prompt_template)\n",
        "\n",
        "# Test the few-shot prompting with sample product reviews\n",
        "reviews_to_classify = [\n",
        "    \"The headphones have excellent sound quality, totally worth the price!\",\n",
        "    \"I'm not happy, the phone case broke after two days of use.\",\n",
        "    \"The product is fine, but I don’t feel strongly about it either way.\"\n",
        "]\n",
        "\n",
        "for review in reviews_to_classify:\n",
        "    result = few_shot_chain.invoke({\"review\": review}).content\n",
        "    print(f\"Review: {review}\")\n",
        "    print(f\"{result}\\n\")\n"
      ],
      "metadata": {
        "id": "chyQ5bD-dmOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3316fc2f-d4ff-49ba-d4c7-00c933b1633c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: The headphones have excellent sound quality, totally worth the price!\n",
            "Sentiment: positive\n",
            "\n",
            "Review: I'm not happy, the phone case broke after two days of use.\n",
            "Review: I'm not happy, the phone case broke after two days of use.\n",
            "Sentiment: negative\n",
            "\n",
            "Review: The product is fine, but I don’t feel strongly about it either way.\n",
            "Review: The product is fine, but I don’t feel strongly about it either way.\n",
            "Sentiment: neutral\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chain of Thought Prompting**"
      ],
      "metadata": {
        "id": "Td6R8U4FoTU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Chain of Thought prompt\n",
        "cot_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Answer the following question step by step concisely: {question}\"\n",
        ")\n",
        "\n",
        "# Create chains\n",
        "\n",
        "cot_chain = cot_prompt | llm\n",
        "\n",
        "# Example question\n",
        "question = \"\"\"A cylindrical water tank with a radius of 1.5 meters and a height of 4 meters is 2/3 full.\n",
        "If water is being added at a rate of 10 liters per minute, how long will it take for the tank to overflow?\n",
        "Give your answer in hours and minutes, rounded to the nearest minute.\n",
        "(Use 3.14159 for π and 1000 liters = 1 cubic meter)\"\"\"\n",
        "\n",
        "# Get responses\n",
        "\n",
        "cot_response = cot_chain.invoke(question).content\n",
        "\n",
        "\n",
        "print(\"\\nChain of Thought Response:\")\n",
        "print(cot_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBFUU1WxnQr0",
        "outputId": "d85fa805-70c7-45a5-eb93-a1c8e7c32a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chain of Thought Response:\n",
            "To find the time it takes for the tank to overflow, we need to follow these steps:\n",
            "\n",
            "1. **Find the volume of the tank:**\n",
            "   - The formula for the volume of a cylinder is V = πr²h, where r is the radius and h is the height.\n",
            "   - Given radius (r) = 1.5 meters and height (h) = 4 meters.\n",
            "   - Volume (V) = π * (1.5)² * 4 = 3.14159 * 2.25 * 4 = 28.26 cubic meters.\n",
            "\n",
            "2. **Find the volume of water already in the tank:**\n",
            "   - Since the tank is 2/3 full, we multiply the total volume by 2/3.\n",
            "   - Volume already in the tank = 28.26 * 2/3 = 18.84 cubic meters.\n",
            "\n",
            "3. **Find the remaining volume needed to overflow:**\n",
            "   - Total volume - Volume already in the tank = 28.26 - 18.84 = 9.42 cubic meters.\n",
            "\n",
            "4. **Convert the remaining volume to liters:**\n",
            "   - 1 cubic meter = 1000 liters.\n",
            "   - Remaining volume in liters = 9.42 * 1000 = 9420 liters.\n",
            "\n",
            "5. **Find the time it takes to fill the remaining volume:**\n",
            "   - Rate of water addition = 10 liters per minute.\n",
            "   - Time = Remaining volume / Rate = 9420 / 10 = 942 minutes.\n",
            "\n",
            "6. **Convert the time from minutes to hours and minutes:**\n",
            "   - 942 minutes = 15 hours and 42 minutes.\n",
            "\n",
            "Therefore, it will take approximately 15 hours and 42 minutes for the tank to overflow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt Chaining**"
      ],
      "metadata": {
        "id": "DL3HK4R3hEKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# Define prompt templates and chains\n",
        "prompts = {\n",
        "    \"summarize\": (\"review\", \"Summarize the following customer review into a single sentence:\\n\\nReview: {review}\\n\\nSummary:\"),\n",
        "    \"sentiment\": (\"summary\", \"Classify the sentiment of the following review summary as positive, negative, or neutral:\\n\\nSummary: {summary}\\n\\nSentiment:\"),\n",
        "    \"suggest\": (\"sentiment\", \"Based on the following sentiment, provide a brief suggestion for the seller:\\n\\nSentiment: {sentiment}\\n\\nSuggestion:\")\n",
        "}\n",
        "\n",
        "chains = {}\n",
        "for key, (var, template) in prompts.items():\n",
        "\n",
        "    prompt = PromptTemplate(input_variables=[var], template=template)\n",
        "    chains[key] = prompt | llm\n",
        "\n",
        "# Helper to extract content\n",
        "def extract_content(x):\n",
        "    return x.content if hasattr(x, \"content\") else str(x)\n",
        "\n",
        "# Helper to wrap output into dict for next chain\n",
        "def wrap_output(key):\n",
        "    return lambda x: {key: extract_content(x)}\n",
        "\n",
        "# Compose full chain\n",
        "full_chain = (\n",
        "    chains[\"summarize\"]\n",
        "    | RunnableLambda(wrap_output(\"summary\"))\n",
        "    | chains[\"sentiment\"]\n",
        "    | RunnableLambda(wrap_output(\"sentiment\"))\n",
        "    | chains[\"suggest\"]\n",
        ")\n",
        "\n",
        "# Example review\n",
        "review = \"The product arrived late and was slightly damaged. I am very disappointed with the quality and the delivery service. I would not recommend this product.\"\n",
        "\n",
        "# Run chain\n",
        "result = full_chain.invoke({\"review\": review})\n",
        "suggestion = extract_content(result)\n",
        "\n",
        "print(f\"Review:\\n{review}\\n\")\n",
        "print(f\"Suggestion:\\n{suggestion}\")\n"
      ],
      "metadata": {
        "id": "oWTWyfuuhGOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf5c4bfe-e84a-452b-85a9-b4ee9bd9b722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review:\n",
            "The product arrived late and was slightly damaged. I am very disappointed with the quality and the delivery service. I would not recommend this product.\n",
            "\n",
            "Suggestion:\n",
            "Based on the customer's extremely negative sentiment, a brief suggestion for the seller could be:\n",
            "\n",
            "\"Refund the full order amount immediately and offer a prepaid return shipping label to ensure the damaged goods are returned to the company. Additionally, provide a prepaid shipping label for a replacement order to be sent out as soon as possible, ensuring that the new shipment arrives in pristine condition. This gesture will help to rectify the situation and potentially salvage the customer's trust in the company.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**System Message & Human Message**"
      ],
      "metadata": {
        "id": "5V_8ga15w7MK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "def translate_to_hindi(human_message_content: str):\n",
        "    \"\"\"\n",
        "    Translates an English sentence to Hindi using the language model.\n",
        "\n",
        "    Args:\n",
        "        human_message_content: The English sentence to translate.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        SystemMessage(content=\"You are a helpful assistant that translates English to Hindi. Just translate the given sentence. Do not answer the question\"),\n",
        "        HumanMessage(content=human_message_content)\n",
        "    ]\n",
        "    response = llm.invoke(messages)\n",
        "    print(response.content)\n"
      ],
      "metadata": {
        "id": "I13KAUWHvM2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate_to_hindi(\"Delhi has Qutub Minar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E8E_fyZv7Xi",
        "outputId": "8b83b818-14c9-461f-a6f5-6dae80ca34ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "दिल्ली में कुतुब मीनार है।\n"
          ]
        }
      ]
    }
  ]
}